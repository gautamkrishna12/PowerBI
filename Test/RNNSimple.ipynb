{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746c07e8-e80f-4293-ac2b-8162ea105bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN,Dense,Embedding,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5781e6b-1cd6-4db3-b7f8-642bf216f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=1000)\n",
    "\n",
    "pad_train=pad_sequences(X_train,maxlen=500,padding='post')\n",
    "\n",
    "pad_test=pad_sequences(X_test,maxlen=500,padding='post')\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_loss',patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868ffa6c-96fc-4b2b-ad6e-009a7b0d3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=1000,output_dim=128))\n",
    "model.add(SimpleRNN(units=128,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ae63e9-1922-4092-9a02-bac46a8d6453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - accuracy: 0.5014 - loss: 0.6930 - val_accuracy: 0.5058 - val_loss: 0.6920\n",
      "Epoch 2/15\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - accuracy: 0.5145 - loss: 1.4467 - val_accuracy: 0.4998 - val_loss: 0.6937\n",
      "Epoch 3/15\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.5131 - loss: 0.6914 - val_accuracy: 0.5070 - val_loss: 0.6924\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(pad_train,y_train,epochs=15,validation_split=0.2,batch_size=128,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c572839-19e6-4a9c-96b8-c04f3a5a346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92392bc3-78be-4aff-b551-4288c99d3826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Load the IMDb word index dictionary\n",
    "    word_index = imdb.get_word_index()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    tokenizer = Tokenizer(num_words=10000)\n",
    "    tokenizer.word_index = word_index\n",
    "    \n",
    "    # Convert text to a sequence of word indices\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    \n",
    "    # Pad the sequence to match the training data length (500)\n",
    "    padded_sequence = pad_sequences(sequences, maxlen=500)\n",
    "    \n",
    "    # Predict sentiment (0 for negative, 1 for positive)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    \n",
    "    return sentiment\n",
    "\n",
    "# Example usage\n",
    "text = \"The movie was fantastic! Really enjoyed it.\"\n",
    "print(\"Sentiment:\", predict_sentiment(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ca438fb-e715-4f34-92d6-2867b5763b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=imdb.get_word_index()\n",
    "tokenizer=Tokenizer(num_words=1000)\n",
    "tokenizer.word_index=word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a2e944-7c69-4673-abcb-0ec1016299e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=tokenizer.texts_to_sequences([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6d47ec2-0d8f-4075-a44f-5efd5a143b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 17, 13, 774, 63, 507, 9]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ffcca-6658-4f6c-b81f-3218dcf3c28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
